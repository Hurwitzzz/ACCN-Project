1. Managed to implement single Conv Layer working on FPGA. Our program can pass the lab3 test generated by gentest.py on FPGA.
2. Managed to do Tensor inference and Benchmark on Board.
3. Reuse data:
	a.















How do we interface between CPU and FPGA:
0. We used PYNQ_API.
1. We allocated shared memory for X, W, B, Z of each conv layer. And each shared memory's size is equal to the max_size of layers in the MediumNet
2. Pass the virtual pointers of shared memorys to virtual pointers to copy data into shared memory. We only copy weights for one conv layer into shared_memory each time, in order to overlap CPU and FPGA (CPU load weight and FPGA do inference meanwhile). Another reason to do this is shared_memory will overflow if we want to load all weights one time.
3. Pass the physical_address of shared_memory to hls_buffer through axilite so that m_axi knows from where to get the data.
4. After inference of each layer, we transfer the result of ReLu back to CPU



Analyze difference in the two layers and how they differ from each other.

